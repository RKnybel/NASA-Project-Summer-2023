{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519336b0",
   "metadata": {},
   "source": [
    "# MSLNet Image Classifier for the MSL Dataset with Class Weights\n",
    "This classifier aims to reproduce the Caffe model used in the paper, \"Deep Mars: CNN Classification of MarsImagery for the PDS Imaging Atlas\"\n",
    "\n",
    "-Riley Knybel 8/2/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cb717",
   "metadata": {},
   "source": [
    "## Part 1/3: Prepare Hardware and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea1ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 06:38:55.539455: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-06 06:38:56.260964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow and other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import os\n",
    "img_folder = \"msl-images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923f714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 06:38:59.515538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-06 06:38:59.542839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-06 06:38:59.542989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow GPU memory allocation fix\n",
    "#https://github.com/tensorflow/tensorflow/issues/35264\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03493e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6690 total images in dataset\n"
     ]
    }
   ],
   "source": [
    "#count the images in the dataset\n",
    "count = 0\n",
    "cpt = sum([len(files) for r, d, files in os.walk(img_folder)])\n",
    "print(str(cpt) + \" total images in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a610242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset using Keras\n",
    "\n",
    "#SPLIT\n",
    "#Train/Validate/Test\n",
    "#70%/15%/15%\n",
    "\n",
    "batch_size = 4\n",
    "img_height = 227\n",
    "img_width = 227\n",
    "\n",
    "#training/validation split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    img_folder,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_and_test = tf.keras.utils.image_dataset_from_directory(\n",
    "  img_folder,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds, test_ds = tf.keras.utils.split_dataset(val_and_test, left_size=0.5)\n",
    "\n",
    "val_size = len(val_ds) * batch_size\n",
    "test_size = len(test_ds) * batch_size\n",
    "\n",
    "print(\"True validation size: \" + str(val_size))\n",
    "print(\"True test size: \" + str(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f0e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6690 images belonging to 24 classes.\n",
      "{0: 3.484375, 1: 11.614583333333334, 2: 7.743055555555555, 3: 1.5838068181818181, 4: 4.72457627118644, 5: 0.5508893280632411, 6: 4.223484848484849, 7: 1.720679012345679, 8: 0.10385618479880775, 9: 0.7513477088948787, 10: 1.006317689530686, 11: 10.721153846153847, 12: 2.3824786324786325, 13: 4.099264705882353, 14: 1.8218954248366013, 15: 2.534090909090909, 16: 3.241279069767442, 17: 2.0346715328467155, 18: 12.670454545454545, 19: 4.099264705882353, 20: 3.926056338028169, 21: 1.39375, 22: 1.444300518134715, 23: 0.2793086172344689}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set the image size and batch size\n",
    "img_height = 227\n",
    "img_width = 227\n",
    "batch_size = 32\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation and loading the dataset\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,   # Normalize pixel values to [0, 1]\n",
    "    # Add other data augmentation parameters as needed\n",
    ")\n",
    "\n",
    "# Load the dataset using ImageDataGenerator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    img_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,       # Important: Shuffle the data to avoid issues with class weighting\n",
    "    seed=123            # Set seed for reproducibility\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "\n",
    "\n",
    "# Convert class weights to a dictionary format\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa1999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48420ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data - change pixel scale from 0-255 to 0-1\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9d168",
   "metadata": {},
   "source": [
    "## Part 2/3: Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7935e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alexnet\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(img_height, img_width,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(24, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the layers!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63306ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd074d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model, time to cook!\n",
    "\n",
    "\n",
    "#set up tensorboard\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#repeat is used to make sure there is enough training data for 3000 iterations\n",
    "epochs=6\n",
    "steps_per_epoch=int(cpt/batch_size)\n",
    "print(steps_per_epoch)\n",
    "\n",
    "history = model.fit(\n",
    "  train_generator,\n",
    "  epochs=epochs,\n",
    "  validation_split=0.1,\n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  callbacks=[tensorboard_callback],\n",
    "  class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98553c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ad273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a0cb9",
   "metadata": {},
   "source": [
    "## Part 3/3: Evaluation and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68375a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the accuracy\n",
    "score = model.evaluate(val_ds, verbose=0)\n",
    "print(\"Validation Loss: \" + str(score[0]))\n",
    "print(\"Validation Accuracy: \" + str(score[1]))\n",
    "\n",
    "score = model.evaluate(test_ds, verbose=0)\n",
    "print(\"Test Loss: \" + str(score[0]))\n",
    "print(\"Test Accuracy: \" + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18682c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
