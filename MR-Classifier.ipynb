{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519336b0",
   "metadata": {},
   "source": [
    "# MRNet Image Classifier for the MSL Dataset\n",
    "This is a model to classify images from the Right Mastcam on the Curiosity rover.\n",
    "\n",
    "There are three parts:\n",
    "1. Prepare Hardware and Data\n",
    "2. Building and Training\n",
    "3. Evaluation and Predictions\n",
    "\n",
    "-Riley Knybel 7/16/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cb717",
   "metadata": {},
   "source": [
    "## Part 1/3: Prepare Hardware and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea1ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:44:02.011927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 13:44:02.754706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow and other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import os\n",
    "img_folder = \"mr-images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923f714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 13:44:03.307445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 13:44:03.333510: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16439/972199872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#https://github.com/tensorflow/tensorflow/issues/35264\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Tensorflow GPU memory allocation fix\n",
    "#https://github.com/tensorflow/tensorflow/issues/35264\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03493e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2402 total images in dataset\n"
     ]
    }
   ],
   "source": [
    "#count the images in the dataset\n",
    "count = 0\n",
    "cpt = sum([len(files) for r, d, files in os.walk(img_folder)])\n",
    "print(str(cpt) + \" total images in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a610242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2402 files belonging to 15 classes.\n",
      "Using 1682 files for training.\n",
      "Found 2402 files belonging to 15 classes.\n",
      "Using 720 files for validation.\n",
      "True validation size: 360\n",
      "True test size: 360\n"
     ]
    }
   ],
   "source": [
    "#load the dataset using Keras\n",
    "\n",
    "#SPLIT\n",
    "#Train/Validate/Test\n",
    "#70%/15%/15%\n",
    "\n",
    "batch_size = 4\n",
    "img_height = 227\n",
    "img_width = 227\n",
    "\n",
    "#training/validation split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    img_folder,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_and_test = tf.keras.utils.image_dataset_from_directory(\n",
    "  img_folder,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds, test_ds = tf.keras.utils.split_dataset(val_and_test, left_size=0.5)\n",
    "\n",
    "val_size = len(val_ds) * batch_size\n",
    "test_size = len(test_ds) * batch_size\n",
    "\n",
    "print(\"True validation size: \" + str(val_size))\n",
    "print(\"True test size: \" + str(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f0e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apxs', 'chemcam cal target', 'drill\\n', 'drt front', 'drt side', 'ground', 'horizon', 'mahli', 'mastcam cal target', 'observation tray', 'portion box', 'portion tube', 'portion tube opening', 'rover rear deck', 'scoop']\n"
     ]
    }
   ],
   "source": [
    "# show class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48420ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#normalize data - change pixel scale from 0-255 to 0-1\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9d168",
   "metadata": {},
   "source": [
    "## Part 2/3: Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7935e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alexnet\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(img_height, img_width,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcd6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44e4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 55, 55, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 27, 27, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 27, 27, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 13, 13, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 13, 13, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 13, 13, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                65552     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58352400 (222.60 MB)\n",
      "Trainable params: 58349648 (222.59 MB)\n",
      "Non-trainable params: 2752 (10.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#see the layers!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63306ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd074d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/.local/lib/python3.10/site-packages/keras/src/backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 328s 654ms/step - loss: 2.9975 - accuracy: 0.6992 - val_loss: 1.9783 - val_accuracy: 0.6806\n",
      "Epoch 2/6\n",
      "500/500 [==============================] - 329s 658ms/step - loss: 1.8512 - accuracy: 0.7948 - val_loss: 1.3588 - val_accuracy: 0.8500\n",
      "Epoch 3/6\n",
      "500/500 [==============================] - 439s 879ms/step - loss: 1.2216 - accuracy: 0.8504 - val_loss: 1.9111 - val_accuracy: 0.6861\n",
      "Epoch 4/6\n",
      "500/500 [==============================] - 327s 655ms/step - loss: 0.8359 - accuracy: 0.8864 - val_loss: 43.1684 - val_accuracy: 0.6333\n",
      "Epoch 5/6\n",
      "500/500 [==============================] - 327s 654ms/step - loss: 0.6030 - accuracy: 0.9029 - val_loss: 0.4086 - val_accuracy: 0.9333\n",
      "Epoch 6/6\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.9188"
     ]
    }
   ],
   "source": [
    "#train the model, time to cook!\n",
    "\n",
    "#repeat is used to make sure there is enough training data for 3000 iterations\n",
    "\n",
    "epochs=6\n",
    "steps_per_epoch=500\n",
    "history = model.fit(\n",
    "  train_ds.repeat(9),\n",
    "  validation_data=val_ds.repeat(9),\n",
    "  epochs=epochs,\n",
    "  steps_per_epoch=steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ad273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a0cb9",
   "metadata": {},
   "source": [
    "## Part 3/3: Evaluation and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68375a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the accuracy\n",
    "score = model.evaluate(val_ds, verbose=0)\n",
    "print(\"Validation Loss: \" + str(score[0]))\n",
    "print(\"Validation Accuracy: \" + str(score[1]))\n",
    "\n",
    "score = model.evaluate(test_ds, verbose=0)\n",
    "print(\"Test Loss: \" + str(score[0]))\n",
    "print(\"Test Accuracy: \" + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the confusion matrix\n",
    "\n",
    "# predict on the validation dataset\n",
    "validation_predictions = model.predict(validation_generator)\n",
    "# Convert predicted probabilities to class labels\n",
    "predicted_labels = np.argmax(validation_predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(validation_generator.classes, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00758c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
